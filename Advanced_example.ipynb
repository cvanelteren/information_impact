{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 6,
        "hidden": false,
        "row": 0,
        "width": null
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Relation between mutual information and causation\n",
    "\n",
    "Due to some comments made by Rick, I was triggered in narrowing down the relation between how information theoretical metrics are related to causal relations. In particular how can we deduce from mutual information between a node $s_i$ and the system $S$ that the relation is in fact causal?\n",
    "\n",
    "\n",
    "An inflated mutual information value could occur when we have a so-called confounder, i.e. where the node could not possible have a causal effect on the system as is found when computing its mutual information.\n",
    "A study case would be the following graph:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": true
       }
      }
     }
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempted relative import beyond top-level package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-10a6ff1ffe6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUtils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplotting\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplotz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'seaborn-poster'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# graph = nx.path_graph(5)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: attempted relative import beyond top-level package"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "from ..Utils import plotting as plotz\n",
    "import matplotlib.pyplot as plt, numpy as np\n",
    "plt.style.use('seaborn-poster')\n",
    "# graph = nx.path_graph(5)\n",
    "# graph = nx.path_graph(5, nx.DiGraph()) # directed\n",
    "graph.add_edges_from([(0,5), (5,6)])\n",
    "graph = nx.barabasi_albert_graph(5, 2)\n",
    "\n",
    "pos = {i: np.array(j) * .08 for i, j in nx.nx_agraph.graphviz_layout(graph, prog = 'neato').items()}\n",
    "fig, ax = plt.subplots()\n",
    "plotz.addGraphPretty(graph, ax = ax, positions = pos)\n",
    "ax.axis('off')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 11,
        "hidden": false,
        "row": 6,
        "width": null
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "## Expectations\n",
    "\n",
    "The directed graph has one common source node (0). However, as 0 has no edges It should share 0 mutual information with the system as it cannot interact with the system directly; its state is set randomly. Alternatively, one could argue that its information would be contained the longest in the system as node 0 information has the most downstream nodes. This view would imply that node 5 can be similar to node 1 and thus be confounded through 0. \n",
    "\n",
    "- $I(s_5^{t + t_0} : S^{t_0})$ is confounded\n",
    "- or $I(s_0^{t + t_0} : S^{t_0})$ is confounded\n",
    "\n",
    "# Results\n",
    "\n",
    "## Magnetization matching\n",
    "I matched the magnetization to the critical temperature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 11,
        "hidden": false,
        "row": 17,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from Toolbox import infcy # montecarlo methods\n",
    "from Models import fastIsing # models\n",
    "# match magnetization over temp range\n",
    "temps        = np.linspace(0, graph.number_of_nodes(), 50)\n",
    "nSamples     = 100 # int(1e2)\n",
    "\n",
    "model = fastIsing.Ising(graph)\n",
    "\n",
    "model.magSide    = '' # equal magnetization sampling\n",
    "model.updateType = 'single' # ultra smooth when single\n",
    "\n",
    "\n",
    "mag, sus = model.matchMagnetization(temps, nSamples, burninSamples = 0)\n",
    "\n",
    "from scipy import ndimage\n",
    "sus = ndimage.gaussian_filter1d(sus, 1)\n",
    "mag = ndimage.gaussian_filter1d(mag, 1)\n",
    "sus[np.isfinite(sus) == 0] = 0 # remove nans\n",
    "idx     = np.argsort(sus)[-1] # get 'max' idx ; second is used\n",
    "model.t = temps[idx]\n",
    "\n",
    "# show mag and sus as function of temperature\n",
    "fig, ax = plt.subplots(1, 2)\n",
    "ax[0].scatter(temps, mag, label = 'Magnetization')\n",
    "ax[1].scatter(temps, sus, label = 'Susceptebility')\n",
    "ax[0].axvline(temps[idx], color = 'red', linestyle = 'dashed')\n",
    "ax[1].axvline(temps[idx], color = 'red', linestyle = 'dashed')\n",
    "\n",
    "ax[1].set_title('Susceptibility')\n",
    "ax[0].set_title('Magnetization')\n",
    "mainax = fig.add_subplot(111, frameon = False, \\\n",
    "                         xticks = [],\\\n",
    "                         yticks = [], \\\n",
    "                        )\n",
    "mainax.set_xlabel('Temperature', labelpad = 30)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 28,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Temperature at the red dashed line was used. The low on average magnetization is expected due to the directed nature of the graph. It is less stable as nodes choose states more randomly and are less stabilized with the detailed balance condition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 17,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Mutual information decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 17,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "deltas        = 20             #conditional time steps\n",
    "nSamples      = int(1e3)       # max number of states\n",
    "step          = int(1e3)   \n",
    "burninSamples = 100            # burninSamples + step = sim. steps until sample\n",
    "repeats       = int(1e3)       # number of conditional repeats\n",
    "\n",
    "reverse = False\n",
    "# reverse = True\n",
    "\n",
    "# added reverse case for 'simulating backwards'\n",
    "if reverse:\n",
    "    res = np.zeros((nSamples, model.nNodes))\n",
    "    rngs= np.random.randint(0, model.nNodes, size = nSamples)\n",
    "    for i in range(nSamples):\n",
    "        res[i] = model.updateState(rngs[[i]])\n",
    "    nWindow = deltas\n",
    "    ps = {}\n",
    "    px = np.zeros((nWindow, model.nNodes, model.nStates))\n",
    "    cpx= {}\n",
    "    Z  = (nSamples - 1 - nWindow) \n",
    "\n",
    "    statemapper = {i : idx for idx, i in enumerate([-1, 1])}\n",
    "\n",
    "    c = 0\n",
    "    snapshots = {}\n",
    "    for i in range(nWindow, nSamples - 1):\n",
    "        tmp   = res[i-nWindow : i]\n",
    "        state = tuple(np.array(tmp[-1], dtype = int))\n",
    "        \n",
    "        snapshots[state] = snapshots.get(state, 0) + 1 / Z\n",
    "        c += 1\n",
    "        ps[state] = ps.get(state, 0) + 1\n",
    "        if state not in cpx:\n",
    "            cpx[state] = np.zeros(( nWindow, model.nNodes, model.nStates))\n",
    "        for t, stateAtTime in enumerate(tmp):\n",
    "            for node, nodeState in enumerate(stateAtTime):\n",
    "                px[t, node,   statemapper[nodeState]] += 1 / Z\n",
    "                cpx[state][t, node, statemapper[nodeState]] += 1 \n",
    "    c = 0\n",
    "    rmi = np.zeros((nWindow, model.nNodes))\n",
    "    for state, val in ps.items():\n",
    "        cpx[state] /= val\n",
    "        rmi += np.nansum(cpx[state] * np.log2(cpx[state]), axis = -1) * val / Z\n",
    "    rmi -= np.nansum(px * np.log2(px), axis = -1)\n",
    "#     mi  = rmi[::-1,:]\n",
    "    mi  = rmi\n",
    "    \n",
    "# normal supported forward simulation\n",
    "else:\n",
    "    snapshots   = infcy.getSnapShots(model, nSamples, step, burninSamples)\n",
    "    cpx = infcy.monteCarlo(model, snapshots,\\\n",
    "                          deltas, repeats)\n",
    "    px, rmi = infcy.mutualInformation(cpx, deltas, snapshots, model)\n",
    "    from Utils.stats import panzeriTrevesCorrection\n",
    "    bias = panzeriTrevesCorrection(px, cpx, repeats)\n",
    "    mi = rmi - bias\n",
    "print(mi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 7,
        "hidden": false,
        "row": 21,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize =(20, 10))\n",
    "elements = []\n",
    "x = np.arange(mi.shape[0])\n",
    "colors = plt.cm.tab20(np.arange(graph.number_of_nodes()))\n",
    "from mpl_toolkits.axes_grid.inset_locator import inset_axes\n",
    "\n",
    "inax = inset_axes(ax,\n",
    "                    width  =\"70%\", \n",
    "                    height =\"60%\",\n",
    "                    loc    = 'upper right')\n",
    "plotz.addGraphPretty(graph, ax = inax, \\\n",
    "                     cmap = colors, mapping = model.mapping, \\\n",
    "                     positions = pos)\n",
    "\n",
    "inax.axis('off')\n",
    "for node, nodeidx in sorted(model.mapping.items(), key = lambda x: x[1]):\n",
    "    ax.plot(x, mi[:, node], marker ='o', color = colors[nodeidx], label = node)\n",
    "    element = plt.Line2D([0],[0], \\\n",
    "                       color = colors[nodeidx], \\\n",
    "                       label = node, \\\n",
    "                       linestyle = 'none',\\\n",
    "                       marker = 'o')\n",
    "    \n",
    "    elements.append(element)\n",
    "ax.legend()\n",
    "ax.set(xlabel = 'Time [step]', \\\n",
    "       ylabel = '$I(s_i^{t + t_0} : S^{t + t_0})$',\\\n",
    "       )\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 21,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "Note some values are overlapping:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 9,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for node, idx in sorted(model.mapping.items(), key = lambda x : x[0]):\n",
    "    print(f'Node: {node}, first 4 values decay {mi[:4, idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "From these results we see the following ranking:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 9,
        "hidden": false,
        "row": 32,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "func = lambda x, a, b, c, d, e, f, g: a + b * np.exp(-c * (x - d)) + e * np.exp(-f * (x - g)) \n",
    "params = dict(maxfev = int(1e6), \\\n",
    "               bounds = (0, np.inf), \\\n",
    "               p0 = np.ones(func.__code__.co_argcount - 1),\\\n",
    "               jac = 'cs',\\\n",
    "             )\n",
    "\n",
    "                          \n",
    "coeffs = plotz.fit(mi.T, func = func, params = params)[0]\n",
    "import scipy\n",
    "auc = [scipy.integrate.quad(lambda x: func(x, *c), 0, deltas // 2)[0] for c in coeffs]\n",
    "for rank, idx in enumerate(np.argsort(auc)[::-1]):\n",
    "    print(f\"Rank {rank + 1} -> node {model.rmapping[idx]}, value : {auc[idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 10,
        "hidden": false,
        "row": 41,
        "width": null
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Interpretation\n",
    "\n",
    "Directed graphs show information impact in a non-intuitive manner. In undirected graphs information impact can be seen as the amount of information sent, i.e. it can be directly interpreted as a measure of dynamic impact. In the directed graphs, the measure will be the 'reverse', i.e. the amount of information received. Thus the node with the slowest decay rate in directed graphs, will be the one that be the last to receive the information. \n",
    "\n",
    "Thus, the MI decay curve above will need to be interpreted with this reverse ranking in mind. Please note that I did think about finding a way to perform nudge dynamics in a reverse way, however I could not find a way where one knows the final state $\\delta$ time steps away. \n",
    "\n",
    "The results seem show:\n",
    "\n",
    "- Node 6 has inflated values as it has no downstream nodes but shows similar decay to node 2 which has 2 downstream nodes\n",
    "- Similarly, node 5 is inflated as it has similar decay to node 1, which has more downstream nodes than 5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 36,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Validation\n",
    "\n",
    "In order to validate the results, we compute the causal impact through nudging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 12,
        "hidden": false,
        "row": 51,
        "width": 4
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nudge  = 100\n",
    "pulses = {node : nudge for node in model.mapping}\n",
    "# pulses = {2 : nudge}\n",
    "pstar = {}\n",
    "\n",
    "for (node, pulse) in pulses.items():\n",
    "    print(f\"Nudging {node} with {pulse}\")\n",
    "    model.nudges = {node : pulse}\n",
    "    print(model.nudges.base)\n",
    "    conditionalstar, p_, mi_ = infcy.runMC(model, snapshots, deltas, repeats)\n",
    "    pstar[node] = p_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "from Utils import stats\n",
    "fig, ax = plt.subplots(1, 2, figsize = (20, 10))\n",
    "elements = []\n",
    "\n",
    "idx = np.arange(graph.number_of_nodes())\n",
    "\n",
    "for k, v in pstar.items():\n",
    "    nodeidx = model.mapping[k]\n",
    "    \n",
    "#     jdx = [i for i in idx if i != nodeidx]\n",
    "    jdx = idx\n",
    "    kl = stats.JS(px, v)\n",
    "    kl_ = kl[-deltas // 2 + 1:, jdx].sum(-1)\n",
    "    \n",
    "    coeff = plotz.fit(kl_[None, :], func, params = params)[0]\n",
    "    causal_auc = scipy.integrate.quad(lambda x: func(x, *coeff.T), 0, deltas // 2)[0]\n",
    "    ax[0].plot(kl_, color = colors[nodeidx])\n",
    "    ax[1].scatter(auc[nodeidx], causal_auc, \\\n",
    "                  color = colors[nodeidx])\n",
    "    \n",
    "    ax[0].plot(kl[:, jdx].sum(-1), color = colors[nodeidx])\n",
    "    \n",
    "    element = plt.Line2D([0],[0], color = colors[nodeidx], \\\n",
    "                      label = k, \\\n",
    "                      linestyle = 'none',\\\n",
    "                      marker = 'o')\n",
    "    elements.append(element)\n",
    "    \n",
    "    \n",
    "\n",
    "ax[0].set(xlabel = 'Time[step]',\\\n",
    "         ylabel = 'Jensen-Shannon divergence')\n",
    "ax[1].set(xlabel = 'information impact', ylabel = 'causal impact')\n",
    "# ax[1].legend(handles = elements, bbox_to_anchor = (1,1), loc = 'upper left')\n",
    "width, height = .5, .5\n",
    "inax = ax[1].inset_axes((1.05, 1-height, width, height), \\\n",
    "                     transform = ax[1].transAxes)\n",
    "inax.axis('off')\n",
    "plotz.addGraphPretty(graph, ax = inax, \\\n",
    "                     cmap = colors, mapping = model.mapping, \\\n",
    "                     positions = nx.circular_layout)\n",
    "ax[1].set_yscale('log'); ax[1].set_xscale('log')\n",
    "inax.axis('off')\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": false,
        "row": 63,
        "width": 12
       },
       "report_default": {
        "hidden": false
       }
      }
     }
    }
   },
   "source": [
    "# Conclusions\n",
    "- For directed graphs using MI is not reliably due to bias but also reflecting receiving and not necessarily causal impact;\n",
    "- For undirected graphs MI seems to reflect causal impact well [results not shown]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "deg = np.fromiter(dict(graph.degree()).values(), dtype = float)\n",
    "ax.hist(deg, bins = 10)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "report_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
