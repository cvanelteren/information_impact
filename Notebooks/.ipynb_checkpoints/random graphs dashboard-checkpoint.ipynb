{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/61 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data...\n",
      "Done\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T17:58:42.306510: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T18:07:21.522523: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T18:17:05.552391: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T18:23:56.883199: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T18:31:32.482352: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T18:38:33.229665: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T18:47:57.741798: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T18:55:19.152393: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T19:04:15.476039: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T19:07:21.493421: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T19:14:08.536856: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T19:20:50.611144: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T19:29:53.983386: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T19:34:40.958054: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T19:42:24.048406: using json\n",
      "loading graph\n",
      "Reading settings in ../Data/new6/2019-06-06T17:58:42.299717/2019-06-06T19:50:59.677603: using json\n",
      "loading graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 59/61 [00:20<00:00,  8.99it/s]\n",
      "  0%|          | 0/61 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 2/61 [00:03<02:43,  2.77s/it]\u001b[A\n",
      "  7%|▋         | 4/61 [00:03<02:09,  2.26s/it]\u001b[A\n",
      "  7%|▋         | 4/61 [00:03<02:09,  2.26s/it]\u001b[A\n",
      "  8%|▊         | 5/61 [00:03<01:33,  1.67s/it]\u001b[A\n",
      " 10%|▉         | 6/61 [00:03<01:07,  1.23s/it]\u001b[A\n",
      " 11%|█▏        | 7/61 [00:03<00:48,  1.12it/s]\u001b[A\n",
      " 13%|█▎        | 8/61 [00:08<01:47,  2.04s/it]\u001b[A\n",
      " 15%|█▍        | 9/61 [00:08<01:16,  1.47s/it]\u001b[A\n",
      " 16%|█▋        | 10/61 [00:08<00:54,  1.07s/it]\u001b[A\n",
      " 20%|█▉        | 12/61 [00:08<00:37,  1.31it/s]\u001b[A\n",
      " 21%|██▏       | 13/61 [00:09<00:27,  1.72it/s]\u001b[A\n",
      " 23%|██▎       | 14/61 [00:09<00:20,  2.24it/s]\u001b[A\n",
      " 25%|██▍       | 15/61 [00:13<01:13,  1.61s/it]\u001b[A\n",
      " 26%|██▌       | 16/61 [00:13<00:52,  1.18s/it]\u001b[A\n",
      " 30%|██▉       | 18/61 [00:13<00:26,  1.60it/s]\u001b[A\n",
      " 30%|██▉       | 18/61 [00:13<00:26,  1.60it/s]\u001b[A\n",
      " 31%|███       | 19/61 [00:14<00:23,  1.75it/s]\u001b[A\n",
      " 33%|███▎      | 20/61 [00:14<00:18,  2.24it/s]\u001b[A\n",
      " 34%|███▍      | 21/61 [00:14<00:16,  2.41it/s]\u001b[A\n",
      " 36%|███▌      | 22/61 [00:18<00:49,  1.28s/it]\u001b[A\n",
      " 38%|███▊      | 23/61 [00:18<00:37,  1.02it/s]\u001b[A\n",
      " 39%|███▉      | 24/61 [00:18<00:29,  1.25it/s]\u001b[A\n",
      " 41%|████      | 25/61 [00:18<00:22,  1.63it/s]\u001b[A\n",
      " 43%|████▎     | 26/61 [00:19<00:17,  1.99it/s]\u001b[A\n",
      "100%|██████████| 61/61 [00:40<00:00,  8.99it/s]\u001b[A\n",
      " 48%|████▊     | 29/61 [00:22<00:22,  1.41it/s]\u001b[A\n",
      " 49%|████▉     | 30/61 [00:22<00:16,  1.86it/s]\u001b[A\n",
      " 54%|█████▍    | 33/61 [00:22<00:08,  3.45it/s]\u001b[A\n",
      " 54%|█████▍    | 33/61 [00:22<00:08,  3.45it/s]\u001b[A\n",
      " 57%|█████▋    | 35/61 [00:22<00:05,  4.54it/s]\u001b[A"
     ]
    }
   ],
   "source": [
    "import numpy as np, sys, os, holoviews as hv, scipy\n",
    "sys.path.insert(0, '../') # add normal modules\n",
    "from Utils import IO, plotting as plotz\n",
    "\n",
    "root = '../Data/new7/2019-06-06T17:58:42.299717'\n",
    "data = IO.DataLoader(root)\n",
    "\n",
    "settings = {k: IO.Settings(os.path.join(root, k)) for k in data}\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing.pool import ThreadPool\n",
    "processes = mp.cpu_count()\n",
    "\n",
    "aucs = loadedData = {}\n",
    "for k, v in data.items():\n",
    "    tmp = os.path.join(root, k)\n",
    "    setting = settings[k]\n",
    "    \n",
    "    tmp_worker = IO.Worker(v, settings[k])\n",
    "    with ThreadPool(processes = processes) as p:\n",
    "        p.map(tmp_worker, tmp_worker.idx)\n",
    "        v = np.frombuffer(tmp_worker.buff, dtype = np.float64).reshape(*tmp_worker.buffshape)    \n",
    "    del tmp_worker\n",
    "    s = v.shape\n",
    "    v = v.reshape(-1, setting.nNodes, setting.deltas // 2 - 1)\n",
    "    v = np.array([(i - i.min()) / (i.max() - i.min()) for i in v])\n",
    "    v = v.reshape(-1, s[-1])\n",
    "    loadedData[k] = v.reshape(s)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# a = next(iter(data))\n",
    "# data[a]['0.8']['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def worker(sample):\n",
    "    # tmp workaround\n",
    "    if len(sample.shape) == 1:\n",
    "        sample = sample.reshape(-1, 1)\n",
    "    auc = np.zeros((len(sample), 2))\n",
    "    auc = np.trapz(sample, axis = -1)\n",
    "    return auc[:, 0]\n",
    "    coeffs, errors = plotz.fit(sample, func, params = fitParam)\n",
    "    for nodei, c in enumerate(coeffs):\n",
    "        tmp = 0\n",
    "        F      = lambda x: func(x, *c)\n",
    "        tmp, _ = scipy.integrate.quad(F, 0, LIMIT)\n",
    "        auc[nodei, 0] = tmp\n",
    "        auc[nodei, 1] = errors[nodei]\n",
    "        if errors[nodei] > .1:\n",
    "            print('error large')\n",
    "    auc[auc < np.finfo(auc.dtype).eps ] = 0\n",
    "    return auc[:, 0]\n",
    "from tqdm import tqdm\n",
    "\n",
    "double = lambda x, a, b, c, d, e, f: a + b * np.exp(-c*(x)) + d * np.exp(- e * (x-f))\n",
    "\n",
    "double_= lambda x, b, c, d, e, f: b * np.exp(-c*(x)) + d * np.exp(- e * (x - f ))\n",
    "single = lambda x, a, b, c : a + b * np.exp(-c * x)\n",
    "single_= lambda x, a, b, c : a + b * np.exp(-c * x)\n",
    "special= lambda x, a, b, c, d: a  + b * np.exp(- (x)**c - d)\n",
    "\n",
    "func        = double\n",
    "p0          = np.ones((func.__code__.co_argcount - 1)); # p0[0] = 0\n",
    "fitParam    = dict(maxfev = int(1e6), \\\n",
    "                   bounds = (0, np.inf), p0 = p0,\\\n",
    "                   jac = 'cs')\n",
    "aucs = {}\n",
    "for k, v in tqdm(loadedData.items()):\n",
    "    setting = settings[k]\n",
    "    LIMIT = setting.deltas // 2 - 1\n",
    "#     LIMIT = np.inf\n",
    "    s = v.shape\n",
    "    v = v.reshape(-1, *s[-2:])\n",
    "    try:\n",
    "        with mp.Pool(mp.cpu_count()) as p:\n",
    "            auc = np.asarray(p.map(worker, v)).reshape(s[:-1])\n",
    "        aucs[k] = auc\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from bokeh import plotting as bp\n",
    "from bokeh.models import ColumnDataSource, CustomJS\n",
    "import bokeh\n",
    "bp.output_notebook()\n",
    "\n",
    "tmp_aucs = np.asarray([i for i in aucs.values()]).squeeze()\n",
    "idx      = np.argmax(tmp_aucs, axis = -1)[:, 0]\n",
    "x = []\n",
    "\n",
    "sets = [0, 2]\n",
    "for jdx, i in enumerate(idx):\n",
    "    tmp = tmp_aucs[jdx,sets, i]\n",
    "    x.append(tmp)\n",
    "\n",
    "tmp_aucs = np.asarray(x)\n",
    "# print(tmp_aucs.shape, idx.shape); assert 0\n",
    "\n",
    "tmp_mi   = np.asarray([loadedData[i] for i in aucs.keys()]).squeeze()\n",
    "tmp_mi   = tmp_mi\n",
    "\n",
    "viridis = bokeh.palettes.Viridis256\n",
    "# setup data\n",
    "buffer          = ColumnDataSource('x', 'y', \\\n",
    "                                   data = dict(x = [], \\\n",
    "                                               y = [], \\\n",
    "                                               color = [])\\\n",
    "                                  )\n",
    "\n",
    "buffer_causal   = ColumnDataSource('x', 'y', \\\n",
    "                                   data = dict(x = [], \\\n",
    "                                               y = [],\\\n",
    "                                              color = []),\\\n",
    "                                  )\n",
    "\n",
    "aucs_bokeh = ColumnDataSource('x', 'y', data = dict(x = tmp_aucs[:, 0], \\\n",
    "                                                    y = tmp_aucs[:, 1], \\\n",
    "                                                    ),\\\n",
    "                             )\n",
    "mi_bokeh    = ColumnDataSource(data = dict(y = tmp_mi[:, 0].tolist()))\n",
    "causal_bokeh= ColumnDataSource(data = dict(y = tmp_mi[:, sets[1]].tolist()))\n",
    "callback = \"\"\"\n",
    "//shorthands\n",
    "\n",
    "//buffers\n",
    "var x = [];\n",
    "var y = [];\n",
    "var yy= [];\n",
    "\n",
    "var indices = cb_obj.indices;\n",
    "var nIndex = indices.length;\n",
    "\n",
    "console.log(cb_obj)\n",
    "var tmp, nNodes, nTime;\n",
    "var idx;\n",
    "\n",
    "var label, labels = ['x', 'y', 'color'];\n",
    "for (var i = 0; i < labels.length; i++){\n",
    "    label = labels[i];\n",
    "    buffer.data[label] = [];\n",
    "    buffer_causal.data[label] = [];\n",
    "}\n",
    "var plt = Bokeh.Plotting;\n",
    "\n",
    "console.log('start debug')\n",
    "var colors_plot;\n",
    "var sep;\n",
    "for (var ni = 0 ; ni < nIndex ; ni++){\n",
    "    // get the data; build the time vector\n",
    "    idx      = indices[ni];\n",
    "    nNodes   = mi.data['y'][idx].length;\n",
    "    sep      = Math.floor(colors.length / nNodes); \n",
    "    \n",
    "    colors_plot = [];\n",
    "    for (var node = 0 ; node < nNodes ; node++){\n",
    "        nTime = mi.data['y'][idx][node].length;\n",
    "        // build time\n",
    "        x = [];\n",
    "        for (var t = 0 ; t < nTime ; t++){\n",
    "            x.push(t);\n",
    "        }\n",
    "        colors_plot.push([colors[node * sep]])\n",
    "        y = mi.data['y'][idx][node];\n",
    "        buffer.data['x'].push(x);\n",
    "        buffer.data['y'].push(y);\n",
    "         \n",
    "        yy = causal.data['y'][idx][node];\n",
    "        buffer_causal.data['x'].push(x);\n",
    "        buffer_causal.data['y'].push(yy);\n",
    "        \n",
    "        buffer_causal.data['color'].push(colors[sep * node])\n",
    "        \n",
    "        buffer.data['color'].push(colors[sep * node])\n",
    "        }\n",
    "    \n",
    "    console.log(buffer.data['y'].length, colors_plot.length)\n",
    "}\n",
    "buffer.change.emit();\n",
    "buffer_causal.change.emit();\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "f1 = bp.figure(tools = 'hover tap lasso_select'.split(), width = 300)\n",
    "f2 = bp.figure( height = int(f1.plot_height * .5 ))\n",
    "f3 = bp.figure( height = int(f1.plot_height * .5 ))\n",
    "\n",
    "f1.scatter('x', 'y', source = aucs_bokeh, size = 10)\n",
    "f2.multi_line('x', 'y', source = buffer, color = 'color')\n",
    "f3.multi_line(xs = 'x', ys = 'y', source = buffer_causal, color = 'color')\n",
    "JS =  CustomJS(\\\n",
    "             args = dict(buffer = buffer, \\\n",
    "                         mi     = mi_bokeh, \\\n",
    "                         buffer_causal = buffer_causal, \\\n",
    "                         causal = causal_bokeh, \n",
    "                         colors = bokeh.palettes.Magma256,\\\n",
    "              ),\\\n",
    "             code = callback)\n",
    "aucs_bokeh.selected.js_on_change('indices', \\\n",
    "                                JS)\n",
    "bp.show(bokeh.layouts.row(f1, bokeh.layouts.column(f2, f3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp_aucs = np.asarray([i for i in aucs.values()]).squeeze()\n",
    "\n",
    "# tmp_aucs = np.sort(tmp_aucs, axis = -1)[..., -1:]\n",
    "\n",
    "# print(tmp_aucs.shape)\n",
    "# fig, ax = plt.subplots()\n",
    "# colors = plt.cm.Spectral(np.linspace(0, 1, len(tmp_aucs)))\n",
    "# [ax.scatter(*i[:2], color = colors[idx]) for idx, i in enumerate(tmp_aucs)]\n",
    "# fig.show()\n",
    "aucs = {}\n",
    "for k, v in loadedData.items():\n",
    "    aucs[k] = np.trapz(v.squeeze(), axis = -1)\n",
    "    print(aucs[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.cm.Spectral?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import style\n",
    "import matplotlib.pyplot as plt\n",
    "style.reload_library()\n",
    "%matplotlib inline\n",
    "style.use('seaborn-poster')\n",
    "fig, ax = plt.subplots(3,1, sharex = 'all')\n",
    "labels = '0.5 1 inf'.split()\n",
    "print(len(aucs))\n",
    "for k, v in aucs.items():\n",
    "    tmp = v.squeeze()\n",
    "    jdx = np.argsort(tmp, axis = -1)[:, -1]\n",
    "#     print([tmp[i, j] for i, j in enumerate(jdx)])\n",
    "    for idx, axi in enumerate(ax):\n",
    "        y = tmp[[0, idx + 1]]\n",
    "        axi.scatter(*y[:, jdx[idx + 1]], color = 'blue', alpha = .2)\n",
    "#         axi.scatter(*tmp[[0, idx + 1]].max(-1), color = 'red', alpha = .2)\n",
    "        axi.set_title(labels[idx])\n",
    "    \n",
    "mainax = fig.add_subplot(111, frameon = 0, xticks = [], yticks = [])\n",
    "mainax.set(xlabel = 'Informational impact', ylabel = 'Causal impact')\n",
    "\n",
    "fig.subplots_adjust(wspace = .3)\n",
    "\n",
    "axi.legend(handles = [plt.Line2D([0], [0], color = i, label = j) for i, j in zip(\\\n",
    "                    'blue red'.split(), 'matched max'.split())], bbox_to_anchor = (1.15, 1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "perc = np.zeros((len(aucs), 2))\n",
    "\n",
    "# fig, ax = plt.subplots(3, 1, figsize = (10, 16))\n",
    "colors = plt.cm.gist_ncar(np.linspace(0, 1, len(aucs)))\n",
    "\n",
    "labels = \"Informational impact\\tUnderwhelming causal\".split('\\t')\n",
    "for idx, (k, v) in enumerate(aucs.items()):\n",
    "    \n",
    "    tmp = np.argsort(v.squeeze(), axis = -1)[:, -1]\n",
    "    perc[idx] = tmp[[0]] == tmp[[1, 2]]\n",
    "    if not perc[idx, 0]:\n",
    "        d = loadedData[k].squeeze()\n",
    "        gs = dict(\\\n",
    "                 width_ratios = [1, 1, 1]\\\n",
    "                 )\n",
    "        fig, ax = plt.subplots(1,3, gridspec_kw = gs)\n",
    "        \n",
    "        mainax = fig.add_subplot(111, \\\n",
    "                 frameon = 0, xticks = [], yticks = [])\n",
    "        mainax.set_title(k, pad = 25)\n",
    "        colors = plt.cm.Spectral(np.linspace(0, 1, settings[k].nNodes))\n",
    "        g = settings[k].graph\n",
    "        g = nx.node_link_graph(g)\n",
    "        pos    = nx.circular_layout(g)\n",
    "        subset = np.argsort(v.squeeze(), -1)[:, -2:]\n",
    "        print(subset)\n",
    "        for kk, axi in enumerate(ax[:2]):\n",
    "            sub = subset[kk]\n",
    "            [axi.plot(i, color = c, alpha = .4) for i, c in zip(d[kk, sub], colors[sub])]\n",
    "            axi.set_title(labels[kk])\n",
    "        nx.draw_networkx_nodes(g, pos = pos, node_color = colors, ax = ax[-1])\n",
    "        nx.draw_networkx_edges(g, pos = pos, ax = ax[-1])\n",
    "        ax[-1].set_aspect('equal', 'box')\n",
    "        ax[-1].axes.axis('off')\n",
    "        \n",
    "            \n",
    "        \n",
    "#     vv = loadedData[k]\n",
    "#     for jdx, label in enumerate(tmp):\n",
    "#         axi = ax[jdx]\n",
    "#         d = loadedData[k].squeeze()\n",
    "#         print(d.shape)\n",
    "#         axi.scatter(*d[[0, jdx + 1], label, :])\n",
    "#         axi.plot(vv.squeeze()[jdx, label, :])\n",
    "        \n",
    "    \n",
    "print(perc.mean(0), perc.std(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for k, v in aucs.items():\n",
    "    ax.scatter(*v[[0,1]].squeeze())\n",
    "fig.savefig('test.png')\n",
    "\n",
    "import networkx as nx\n",
    "nx.from_pan\n",
    "nx.from_edgelist([[0,1], [1,0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
