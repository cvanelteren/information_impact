{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named ising",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-dc723b5ade27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpathos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiprocessing\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mising\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named ising"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as ss\n",
    "import copy\n",
    "import time\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import csv\n",
    "import cPickle as pickle\n",
    "from collections import Counter\n",
    "import pathos.multiprocessing as mp\n",
    "\n",
    "import ising\n",
    "\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some initial runs, tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = 'async'  # 'single' means that a random single spin is selected to select its new state (according to Glauber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.\n",
    "system = ising.IsingNetwork(graph=0.3, size=10, T=T, weights=[-1,1], hs=[-1,1])  # weighted, pos and neg\n",
    "# system = ising.IsingNetwork(graph=0.3, size=10, T=T, weights=1, hs=1)  # unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print system.states\n",
    "system.next(trans=trans)\n",
    "print system.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.graph_numbered.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.graph_numbered.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(map(lambda x: x[1]['h'], system.graph_numbered.nodes(data=True)))\n",
    "sns.plt.xlabel('External magnetization coefficients $h_i$ per node')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(map(lambda x: x[2]['weight'], system.graph_numbered.edges(data=True)))\n",
    "sns.plt.xlabel('Edge weight $J_ij$ per edge')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 2000\n",
    "\n",
    "system.T = 0.1*T\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(sum, system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size, +system.size])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = 0.5*T\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(sum, system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size, +system.size])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = T\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(sum, system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size, +system.size])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = 2*T\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(sum, system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size, +system.size])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_before = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_statespace = [1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(ar, base=2):\n",
    "    cts = np.array(Counter(ar).values())\n",
    "    cts = cts / float(len(cts))\n",
    "\n",
    "    return ss.entropy(cts, base=base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 100\n",
    "num_cur_states = 100\n",
    "num_repeats = 100\n",
    "\n",
    "ising_net = ising.IsingNetwork(size=10, T=1, weights=[-1,1], hs=[-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_states = []\n",
    "ising_net2 = copy.deepcopy(ising_net)\n",
    "for cix in range(num_cur_states):\n",
    "    ising_net2.reset_states()  # first randomize states again\n",
    "    cur_states.append(ising_net2.equilibrate(trans=trans))\n",
    "del ising_net2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.plt.hist(map(sum, cur_states), 2*ising_net.size + 1)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.plt.hist(map(sum, ising_net.go(100000, trans=trans)), 2*ising_net.size + 1)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two histograms above should look roughly similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_sum_cur = np.sum(cur_states)  # to be verified remains the same at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(ising_net.go(num_steps, trans=trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (num_cur_states, num_repeats, num_steps+1, len(ising_net.states))\n",
    "states_sequences = [[[cs] + ising_net.go(num_steps, cur_states=cs, trans=trans)\n",
    "                            for _ in range(num_repeats)]\n",
    "                    for cs in cur_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(states_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (len(ising_net.states), num_steps+1, num_cur_states, num_repeats)\n",
    "states_sequences_t = np.transpose(states_sequences, axes=[3, 2, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(states_sequences_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (len(ising_net.states), num_steps+1, num_cur_states * num_repeats)\n",
    "states_sequences_t_eq = np.reshape(states_sequences_t, states_sequences_t.shape[:2] + (np.product(states_sequences_t.shape[2:]),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (size, num_steps)\n",
    "H_eq = [[entropy(states_sequences_t_eq[nix][six]) for six in xrange(num_steps+1)] for nix in xrange(ising_net.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nix in xrange(ising_net.size):\n",
    "    sns.plt.plot(H_eq[nix])\n",
    "sns.plt.xlabel('Time step $t$')\n",
    "sns.plt.xlabel('Entropy H[x(t)]')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (num_cur_states, size, num_steps)\n",
    "# this is H[x_i(t) | X[0]]\n",
    "H_cond_X0 = [[[entropy(states_sequences_t[nix][six][cix])\n",
    "              for six in xrange(num_steps+1)]\n",
    "             for nix in xrange(ising_net.size)]\n",
    "            for cix in xrange(num_cur_states)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (size, _statespace, # cur states where x0=x)\n",
    "cur_state_ids_where_node_is = [[[cix for cix in xrange(num_cur_states) if cur_states[cix][nix] == x0]\n",
    "                                for x0 in _statespace]\n",
    "                               for nix in xrange(ising_net.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (_statespace, size)\n",
    "P_node_x0 = [[float(len(cur_state_ids_where_node_is[nix][xix])) / len(cur_states)\n",
    "              for nix in xrange(ising_net.size)]\n",
    "             for xix in xrange(len(_statespace))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (_statespace, size, num_steps)\n",
    "# note: the whole \"np.reshape(...)\" is essentially `states_sequences_t_eq` but then conditioned on node `nix` having\n",
    "# state x0 (xix) in the 'current' state\n",
    "H_cond_x0 = [[[entropy(np.reshape(np.take(states_sequences_t, cur_state_ids_where_node_is[nix][xix], axis=2),\n",
    "                                  states_sequences_t.shape[:2] + (len(cur_state_ids_where_node_is[nix][xix]) * num_repeats,))[nix][six])\n",
    "              if len(cur_state_ids_where_node_is[nix][xix]) > 0 else 0\n",
    "               for six in xrange(num_steps+1)]\n",
    "              for nix in xrange(ising_net.size)]\n",
    "             for xix in xrange(len(_statespace))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: (size, num_steps)\n",
    "I_xt_x0 = np.subtract(H_eq, np.transpose(np.sum([P_node_x0[xix] * np.transpose(H_cond_x0[xix])\n",
    "                                    for xix in xrange(len(_statespace))], axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.shape(H_eq)\n",
    "print np.shape(H_cond_x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(P_node_x0[0] * np.transpose(H_cond_x0[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(I_xt_x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(H_cond_X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nix in xrange(ising_net.size):\n",
    "    sns.plt.plot(I_xt_x0[nix])\n",
    "sns.plt.xlabel('Time step $t$')\n",
    "sns.plt.xlabel('Mutual information I[x(0), x(t)]')\n",
    "sns.plt.show()\n",
    "\n",
    "for nix in xrange(ising_net.size):\n",
    "    sns.plt.plot(I_xt_x0[nix][:min(10, len(I_xt_x0[nix]))])\n",
    "sns.plt.xlabel('Time step $t$')\n",
    "sns.plt.xlabel('Mutual information I[x(0), x(t)]')\n",
    "sns.plt.title('Zoom in')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: assuming here that each system state is equally likely!\n",
    "# TODO: weigh by likelihoods?\n",
    "tot_L = np.sum([ising.likelihood(ising_net.graph_numbered, cur_states[cix], ising_net.T) for cix in xrange(len(cur_states))])\n",
    "# shape: (size, num_steps)\n",
    "I_xt_X0 = np.subtract(H_eq, np.transpose(np.sum([ising.likelihood(ising_net.graph_numbered, cur_states[cix], ising_net.T) / tot_L * np.transpose(H_cond_X0[cix])\n",
    "                                    for cix in xrange(len(cur_states))], axis=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ls = [ising.likelihood(ising_net.graph_numbered, cur_states[cix], ising_net.T) for cix in xrange(len(cur_states))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nix in xrange(ising_net.size):\n",
    "    sns.plt.plot(I_xt_X0[nix][:])\n",
    "sns.plt.xlabel('Time step $t$')\n",
    "sns.plt.xlabel('Mutual information I[X(0), x(t)]')\n",
    "sns.plt.show()\n",
    "\n",
    "for nix in xrange(ising_net.size):\n",
    "    sns.plt.plot(I_xt_X0[nix][:][:min(20,len(I_xt_X0[nix][:]))])\n",
    "sns.plt.xlabel('Time step $t$')\n",
    "sns.plt.xlabel('Mutual information I[X(0), x(t)]')\n",
    "sns.plt.title('Zoomed in')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ising.likelihood(ising_net.graph_numbered, cur_states[0], ising_net.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check equality to histogram above, looking for bug\n",
    "sns.plt.hist(map(sum, cur_states), 2*ising_net.size + 1)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pre_sum_cur == np.sum(cur_states), 'cur_states changed! should not be!'  # should be same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print time.time() - time_before, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idt_resp = ising.ce.rel_idts_raw(I_xt_X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(idt_resp.decay_times)\n",
    "sns.plt.xlabel('IDT of a node')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_before = time.time()\n",
    "idt_resp2 = ising.rel_idt_per_node(system, 'single')\n",
    "print time.time() - time_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(idt_resp2.decay_times)\n",
    "sns.plt.xlabel('IDT of a node')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the nudging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.\n",
    "\n",
    "graph = nx.empty_graph(create_using=nx.DiGraph())\n",
    "graph.add_node(0, {'h': 0.0})\n",
    "graph.add_node(1, {'h': 0.0})\n",
    "graph.add_edge(0, 1, {'weight': 1.0})  # small cycle, keeps the system relatively stable in a magnetization\n",
    "graph.add_edge(1, 0, {'weight': 1.0})\n",
    "\n",
    "system = ising.IsingNetwork(graph=graph, T=T, directed=True)  # weighted, pos and neg\n",
    "# system = ising.IsingNetwork(graph=0.3, size=10, T=T, weights=1, hs=1)  # unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.graph_numbered.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.graph_numbered.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ss = system.go(10000, trans=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.reset_states(states=[1, 1])\n",
    "print system.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'node 0:'\n",
    "print ising.energy_node(system.graph_numbered, 0, system.states, T=1.0, state=-1), ising.energy_node(system.graph_numbered, 0, system.states, T=1.0, state=1)\n",
    "print ising.prob_state(system.graph_numbered, 0, system.states, T=1.0, state=-1), ising.prob_state(system.graph_numbered, 0, system.states, T=1.0, state=1)\n",
    "print 'node 1:'\n",
    "print ising.energy_node(system.graph_numbered, 1, system.states, T=1.0, state=-1), ising.energy_node(system.graph_numbered, 1, system.states, T=1.0, state=1)\n",
    "print ising.prob_state(system.graph_numbered, 1, system.states, T=1.0, state=-1), ising.prob_state(system.graph_numbered, 1, system.states, T=1.0, state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 3000\n",
    "\n",
    "system.T = 0.1*T\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(sum, system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size - 0.1, +system.size + 0.1])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = 0.5*T\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(sum, system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size - 0.1, +system.size + 0.1])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = T\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(sum, system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size - 0.1, +system.size + 0.1])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = 2*T\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(sum, system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size - 0.1, +system.size + 0.1])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.add_nudge_to(1, (0., 2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.graph_numbered.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.graph_numbered.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system.graph_numbered.remove_edge(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time ss = system.go(10000, trans=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.go(3, trans=trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.reset_states(states=[1, 1])\n",
    "print system.states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'node 0:'\n",
    "print ising.energy_node(system.graph_numbered, 0, system.states, T=1.0, state=-1), ising.energy_node(system.graph_numbered, 0, system.states, T=1.0, state=1)\n",
    "print ising.prob_state(system.graph_numbered, 0, system.states, T=1.0, state=-1), ising.prob_state(system.graph_numbered, 0, system.states, T=1.0, state=1)\n",
    "print 'node 1:'\n",
    "print ising.energy_node(system.graph_numbered, 1, system.states, T=1.0, state=-1), ising.energy_node(system.graph_numbered, 1, system.states, T=1.0, state=1)\n",
    "print ising.prob_state(system.graph_numbered, 1, system.states, T=1.0, state=-1), ising.prob_state(system.graph_numbered, 1, system.states, T=1.0, state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsteps = 3000\n",
    "\n",
    "system.T = 0.1*T\n",
    "\n",
    "# TODO: nudger nodes should not be taken into account when computing magnetization etc.\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(lambda d: sum(d.itervalues()), system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size - 0.1, +system.size + 0.1])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = 0.5*T\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(lambda d: sum(d.itervalues()), system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size - 0.1, +system.size + 0.1])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = T\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(lambda d: sum(d.itervalues()), system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size - 0.1, +system.size + 0.1])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = 2*T\n",
    "\n",
    "sns.plt.figure(figsize=(21, 8))\n",
    "sns.plt.plot(map(lambda d: sum(d.itervalues()), system.go(nsteps, trans=trans)))\n",
    "sns.plt.ylim([-system.size - 0.1, +system.size + 0.1])\n",
    "sns.plt.show()\n",
    "\n",
    "system.T = T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test state distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 1.\n",
    "\n",
    "graph = nx.empty_graph(create_using=nx.DiGraph())\n",
    "graph.add_node(0, {'h': 0.0})\n",
    "graph.add_node(1, {'h': 0.0})\n",
    "graph.add_edge(0, 1, {'weight': 1.0})  # small cycle, keeps the system relatively stable in a magnetization\n",
    "graph.add_edge(1, 0, {'weight': 1.0})\n",
    "\n",
    "system = ising.IsingNetwork(graph=graph, T=T, directed=True)  # weighted, pos and neg\n",
    "# system = ising.IsingNetwork(graph=0.3, size=10, T=T, weights=1, hs=1)  # unweighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.graph_numbered.edges(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.graph_numbered.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.reset_states([1, 1])\n",
    "print system.state_distributions(30000, trans='async')\n",
    "system.reset_states([1, 1])\n",
    "print system.state_distributions(30000, trans='async')  # repeat a second time to eyeball consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.add_nudge_to(0, (0, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state distributions after nudge\n",
    "system.reset_states([1, 1])\n",
    "print system.state_distributions(30000, trans='async')\n",
    "system.reset_states([1, 1])\n",
    "print system.state_distributions(30000, trans='async')  # repeat a second time to eyeball consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.remove_all_nudges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time system.impact_of_nudge(0, (0.1,  0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try multiple same impact calculations to get an idea of the variance\n",
    "impacts = [system.impact_of_nudge(0, (0.1,  0.0), steps_per_node=10000) for _ in xrange(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(impacts, rug=True)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test nudge impact in a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = ising.generate_directed_powerlaw_network(10, 2.0)\n",
    "\n",
    "print graph.nodes()\n",
    "\n",
    "# add also a disconnected node so that we can test that its nudge impact is indeed zero\n",
    "graph.add_node(graph.number_of_nodes())\n",
    "\n",
    "print graph.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.number_of_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shorthand for all the weights in the network\n",
    "weights = np.array([a['weight'] if a.has_key('weight') else 1.0 \n",
    "                    for (_,_,a) in graph.edges(data=True)])\n",
    "\n",
    "# sns.distplot(weights)\n",
    "# sns.plt.xlabel('weights')\n",
    "# sns.plt.show()\n",
    "\n",
    "# position nodes in the 2D plane using some spring force computation using the weights\n",
    "pos = nx.spring_layout(graph, iterations=20000);\n",
    "\n",
    "edge_label_scale = 100.\n",
    "edge_labels = {(e[0], e[1]): str(round((e[2]['weight'] if e[2].has_key('weight') else 1.0) * edge_label_scale, 1))\n",
    "               for e in graph.edges(data=True)};\n",
    "\n",
    "fig = sns.plt.figure(1, figsize=(12,12));\n",
    "fig.clear();\n",
    "sns.plt.axis('off');\n",
    "nx.draw_networkx_nodes(graph, pos, \n",
    "                       node_size=300., \n",
    "                       node_color=[np.array([0., 0., 0.]) for n1 in graph.nodes_iter()]);\n",
    "nx.draw_networkx_labels(graph, {k: v + [0, +0.03] for (k,v) in pos.iteritems()}, font_weight='bold', \n",
    "                       font_size=16);\n",
    "# nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels);\n",
    "edge_color_baseline = 0.5\n",
    "edge_width_exp = 2.0\n",
    "nx.draw_networkx_edges(graph, pos, width=np.power(weights, edge_width_exp) / np.mean(np.power(weights, edge_width_exp)))\n",
    "#                        edge_color=map(str, edge_color_baseline*np.subtract(weights, min(weights))/max(weights)));\n",
    "\n",
    "# if save_figs:\n",
    "# #     fn = op.join(save_dir, 'skew_diffs_forwardsearch_%srepeats_%s_%s_alpha%s_kz%s_mz%s_uniz%s.pdf' % (num_repeats, X, Y, alpha_multi_fw, kz, mz, int(sample_Z_uniformly)))\n",
    "#     fn = op.join(save_dir, filename_tagged('causal_graph_exp%s' % edge_width_exp, pair=False))\n",
    "#     sns.plt.savefig(fn)\n",
    "#     print 'note: saved to', fn\n",
    "# nx.write_graph6(causal_graph, op.join(save_dir, filename_tagged('causal_graph_exp%s' % edge_width_exp, ext='graph6', pair=False)))\n",
    "# print 'note: graph saved to', op.join(save_dir, filename_tagged('causal_graph_exp%s' % edge_width_exp, ext='graph6', pair=False))\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = ising.IsingNetwork(graph, graph.number_of_nodes(), T=2.0, states=np.ones(graph.number_of_nodes()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(system.graph_numbered.neighbors(graph.number_of_nodes()-1)) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ts, Hs = system.entropy_next_vs_temp()\n",
    "\n",
    "sns.plt.plot(Ts, Hs)\n",
    "sns.plt.xlabel('T')\n",
    "sns.plt.ylabel('<H(s)>')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = system.temp_matching_entropy(0.5)\n",
    "T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.T = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(system.equilibrate()) / system.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.graph_numbered.predecessors(system.size - 1), system.graph_numbered.successors(system.size - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time system.impact_of_nudge(system.size - 1, [0, 1.0], steps_per_node=5000, include_self=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hellinger_null_distribution(n, p, ntrials=20):\n",
    "    hells = []\n",
    "    for i in xrange(ntrials):\n",
    "        succp = np.random.binomial(n, p) / float(n)\n",
    "        failp = 1.0 - succp\n",
    "        succp2 = np.random.binomial(n, p) / float(n)\n",
    "        failp2 = 1.0 - succp2\n",
    "        \n",
    "        hells.append(ising.hellinger_distance([succp, failp], [succp2, failp2]))\n",
    "    return hells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.mean(system.state_distributions(2), axis=0)[0]\n",
    "ns = [500, 1000, 2000, 3000, 5000, 10000]\n",
    "null_hell_per_n = [hellinger_null_distribution(n, p) for n in ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.plt.errorbar(ns, np.mean(null_hell_per_n, axis=1), yerr=np.std(null_hell_per_n, axis=1) / np.sqrt(1))\n",
    "sns.plt.xlabel('Number of samples to estimate state prob.')\n",
    "sns.plt.ylabel('Expected Hellinger distance per node (=nudge impact / size)')\n",
    "sns.plt.title('Null distribution when sampling two identical binomial distributions')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "ns = [500, 1000, 2000, 3000, 5000, 10000]\n",
    "null_hell_per_n = [hellinger_null_distribution(n, p) for n in ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.plt.errorbar(ns, np.mean(null_hell_per_n, axis=1), yerr=np.std(null_hell_per_n, axis=1) / np.sqrt(1))\n",
    "sns.plt.xlabel('Number of samples to estimate state prob.')\n",
    "sns.plt.ylabel('Expected Hellinger distance per node (=nudge impact / size)')\n",
    "sns.plt.title('Null distribution when sampling two identical binomial distributions (p=0.5)')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check performance profile of computing these impacts, they take a bit long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%lprun -f ising.total_network_interaction_energy_node system.impact_of_nudge(0, [0, 1.0], steps_per_node=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute impact for each node with the same nudge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_impact(nix):\n",
    "    return system.impact_of_nudge(nix, [0, 1.0], steps_per_node=20000, include_self=False)\n",
    "\n",
    "time_before = time.time()\n",
    "\n",
    "pool = mp.Pool(6)\n",
    "impacts = pool.map(worker_impact, graph.nodes())\n",
    "pool.close()\n",
    "pool.terminate()\n",
    "\n",
    "print (-time_before + time.time()) / 60., 'minutes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.plt.bar(range(system.size), impacts)\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with network topology features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_degrees = [system.graph_numbered.degree(nix, weight='weight') for nix in range(system.size)]\n",
    "weighted_out_degrees = [system.graph_numbered.out_degree(nix, weight='weight') for nix in range(system.size)]\n",
    "weighted_in_degrees = [system.graph_numbered.in_degree(nix, weight='weight') for nix in range(system.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcdist = nx.centrality.betweenness_centrality(system.graph_numbered, weight='weight')\n",
    "bcs = [bcdist[nix] for nix in range(system.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures_list = [weighted_degrees, weighted_out_degrees, weighted_in_degrees, bcs, np.subtract(weighted_out_degrees, weighted_in_degrees), np.add(weighted_out_degrees, weighted_in_degrees)]\n",
    "xlabels_list = ['weighted_degrees', 'weighted_out_degrees', 'weighted_in_degrees', 'bcs', 'out - in', 'out + in']\n",
    "\n",
    "sns.plt.figure(figsize=(15, 15))\n",
    "\n",
    "for mix, measures in enumerate(measures_list):\n",
    "    sns.plt.subplot(3, 2, len(measures_list) - mix)\n",
    "    sns.distplot(measures)\n",
    "    sns.plt.xlabel(xlabels_list[mix])\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measures_list = [weighted_degrees, weighted_out_degrees, weighted_in_degrees, bcs, np.subtract(weighted_out_degrees, weighted_in_degrees)]\n",
    "# xlabels_list = ['weighted_degrees', 'weighted_out_degrees', 'weighted_in_degrees', 'bcs', 'out - in']\n",
    "\n",
    "sns.plt.figure(figsize=(15, 15))\n",
    "\n",
    "for mix, measures in enumerate(measures_list):\n",
    "    sns.plt.subplot(3, 2, len(measures_list) - mix)\n",
    "    sns.plt.plot(measures, impacts, 'o', markersize=15, alpha=0.5)\n",
    "    sns.plt.xlabel(xlabels_list[mix])\n",
    "    sns.plt.ylabel('Impact of nudge')\n",
    "    if not xlabels_list[mix] in ('out - in',):\n",
    "        sns.plt.xscale('log')\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with IDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_before = time.time()\n",
    "resp = ising.idt_per_node(system, 'async', num_cur_states=300, num_repeats=300, num_steps=50, \n",
    "                          assume_symmetry=False, include_double_exp=True, nprocs=5)\n",
    "print time.time() - time_before, 'seconds'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startix = 0  # keep at 0\n",
    "\n",
    "for nix in xrange(system.size):\n",
    "    sns.plt.plot(resp.mi_over_time[nix][startix:])\n",
    "sns.plt.xlabel('Time step $t$')\n",
    "sns.plt.ylabel('Mutual information I[X(0), x(t)]')\n",
    "# sns.plt.yscale('log')\n",
    "sns.plt.savefig('./mi_over_time_per_node_full_T%s_%s.png' % (system.T, 'async'))\n",
    "sns.plt.show()\n",
    "\n",
    "for nix in xrange(system.size):\n",
    "    sns.plt.plot(resp.mi_over_time[nix][startix:])\n",
    "sns.plt.xlabel('Time step $t$')\n",
    "sns.plt.ylabel('Mutual information I[X(0), x(t)]')\n",
    "sns.plt.yscale('log')\n",
    "sns.plt.title('Log-linear')\n",
    "sns.plt.savefig('./mi_over_time_per_node_full_T%s_%s.png' % (system.T, 'async'))\n",
    "sns.plt.show()\n",
    "\n",
    "for nix in xrange(system.size):\n",
    "    sns.plt.plot(resp.mi_over_time[nix][startix:][:min(20,len(resp.mi_over_time[nix][startix:]))])\n",
    "sns.plt.xlabel('Time step $t$')\n",
    "sns.plt.ylabel('Mutual information I[X(0), x(t)]')\n",
    "sns.plt.title('Zoomed in')\n",
    "sns.plt.savefig('./mi_over_time_per_node_firstpart_T%s_%s.png' % (system.T, 'async'))\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idts_list = [resp.decay_times, resp.decay_times_abs, resp.asymptotic_values]\n",
    "xlabels_idts_list = ['Rel. IDT', 'Abs. IDT', 'Asympt. MI']\n",
    "\n",
    "sns.plt.figure(figsize=(15, 15))\n",
    "\n",
    "for mix, measures in enumerate(idts_list):\n",
    "    sns.plt.subplot(3, 2, len(idts_list) - mix)\n",
    "    sns.plt.plot(measures, impacts, 'o', markersize=15, alpha=0.5)\n",
    "    sns.plt.xlabel(xlabels_idts_list[mix])\n",
    "    sns.plt.ylabel('Impact of nudge')\n",
    "    if xlabels_idts_list[mix] in ('Rel. IDT',):\n",
    "        sns.plt.xscale('log')\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intermezzo: fit a double exponential decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residuals_double_decay(s, xdata, ydata):\n",
    "    '''\n",
    "    Residuals of the curve a*exp(-b*x) + c*exp(-d*x) + plateau\n",
    "    @ s: (a, b, c, d, plateau)\n",
    "    @return: residuals of fitting to xdata, ydata\n",
    "    '''\n",
    "    a, b, c, d, plateau = s\n",
    "    return np.linalg.norm(a*np.exp(-b*xdata) + c*np.exp(-d*xdata) + plateau - ydata)\n",
    "\n",
    "def values_double_decay(s, xdata):\n",
    "    a, b, c, d, plateau = s\n",
    "    return a*np.exp(-b*xdata) + c*np.exp(-d*xdata) + plateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as sopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_double_exp_decay(mi_over_time):\n",
    "    '''\n",
    "    Residuals of the curve a*exp(-b*x) + c*exp(-d*x) + plateau\n",
    "    @ s: (a, b, c, d, plateau)\n",
    "    @return: (a, b, c, d, plateau), making sure that b >= d (so the first exponential is the fast decay).\n",
    "    To calculate the two corresponding relative IDTs (fraction 1/e) you simply do 1/b and 1/d. For the\n",
    "    absolute IDTs to MI=eps do -1/b * np.log(eps/a) and -1/d * np.log(eps/c)\n",
    "    '''\n",
    "    optres = sopt.minimize(residuals_double_decay, \n",
    "                       x0=[0.1, 3., 0.9, 1., 0.],\n",
    "                       args=(np.arange(len(mi_over_time)), np.array(mi_over_time)), \n",
    "                       bounds=[(0., max(mi_over_time)), (0., 100.),\n",
    "                              (0., max(mi_over_time)), (0., 100.),\n",
    "                              (0., max(mi_over_time))])\n",
    "    \n",
    "    if optres.success:\n",
    "        a, b, c, d, plateau = optres.x  # readability\n",
    "        if b < d:\n",
    "            return c, d, a, b, plateau\n",
    "        else:\n",
    "            return a, b, c, d, plateau\n",
    "    else:\n",
    "        raise UserWarning('could not find solution')\n",
    "        \n",
    "\n",
    "def convert_double_exp_s_to_idts(s, epsilon=0.001):\n",
    "    '''\n",
    "    Convert the result of fit_double_exp_decay() to IDT (or equivalently IDL) values, which may be \n",
    "    more meaningful to your users as the units are number of time steps.\n",
    "    @s s: result from fit_double_exp_decay()\n",
    "    @ epsilon: a very small absolute and positive amount of mutual information\n",
    "    @return: (rel IDT 1, rel IDT 2, abs IDT 1, abs IDT 2). \n",
    "    Due to fit_double_exp_decay()'s ordering, rel IDT 2 >= rel IDT 1.\n",
    "    '''\n",
    "    a, b, c, d, plateau = s\n",
    "    return 1/b, 1/d, -1/b * np.log(epsilon / a), -1/d * np.log(epsilon / c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mis = resp.mi_over_time[6]\n",
    "sol = fit_double_exp_decay(mis)\n",
    "print sol\n",
    "sns.plt.plot(mis, 'o')\n",
    "sns.plt.plot(values_double_decay(sol, np.arange(len(mis))))\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rel. IDTs (1/e):\n",
    "1/sol[1], 1/sol[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abs. IDTs (1/e):\n",
    "-1/sol[1] * (np.log(0.001 / sol[0])), -1/sol[3] * (np.log(0.001 / sol[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not hasattr(resp, 'double_exp_idts'):\n",
    "    print 'note: will also compute the double exponential IDTs'\n",
    "    double_exp_s = []\n",
    "    double_exp_idts = []\n",
    "    # as reminder to the caller in what order the IDTs are given in double_exp_idts\n",
    "    double_idt_labels = ('relIDTfast', 'relIDTslow', 'absIDTfast', 'absIDTslow')\n",
    "\n",
    "    for mis in resp.mi_over_time:\n",
    "        s = fit_double_exp_decay(mis)\n",
    "        # expanded for readability:\n",
    "        relIDT1, relIDT2, absIDT1, absIDT2 = convert_double_exp_s_to_idts(s)\n",
    "        double_exp_s.append(s)\n",
    "        double_exp_idts.append((relIDT1, relIDT2, absIDT1, absIDT2))\n",
    "\n",
    "    resp.double_exp_s = double_exp_s\n",
    "    resp.double_exp_idts = double_exp_idts\n",
    "    resp.double_idt_labels = double_idt_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to double expontial decay IDTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(list(np.transpose(resp.double_exp_s)[np.array((0,2))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idts2_list = list(np.transpose(resp.double_exp_idts)) \\\n",
    "            + list([np.transpose(resp.double_exp_s)[-1]]) \\\n",
    "            + list(np.transpose(resp.double_exp_s)[np.array((0,2))]) \\\n",
    "            + list([1.0/(np.transpose(resp.double_exp_s)[2]/np.transpose(resp.double_exp_s)[0])])\n",
    "xlabels2_idts_list = ['relIDT1', 'relIDT2', 'absIDT1', 'absIDT2', 'plateau', 'weight fast', 'weight slow', 'ratio fast/slow weights']\n",
    "\n",
    "sns.plt.figure(figsize=(15, 15))\n",
    "\n",
    "for mix, measures in enumerate(idts2_list):\n",
    "    sns.plt.subplot(4, 2, len(idts2_list) - mix)\n",
    "    sns.plt.plot(measures, impacts, 'o', markersize=15, alpha=0.5)\n",
    "    sns.plt.xlabel(xlabels2_idts_list[mix])\n",
    "    sns.plt.ylabel('Impact of nudge')\n",
    "    if xlabels2_idts_list[mix] in ('absIDT2', 'relIDT2', 'ratio fast/slow weights'):\n",
    "        sns.plt.xscale('log')\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to find a predictive combination of information measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idts2_list = [(np.transpose(resp.double_exp_s)[0]/np.transpose(resp.double_exp_s)[2] * (np.transpose(resp.double_exp_s)[1]+np.transpose(resp.double_exp_s)[3]))]\n",
    "xlabels2_idts_list = ['slow/fast+idt1+idt2']\n",
    "\n",
    "sns.plt.figure(figsize=(15, 15))\n",
    "\n",
    "for mix, measures in enumerate(idts2_list):\n",
    "    sns.plt.subplot(4, 2, len(idts2_list) - mix)\n",
    "    sns.plt.plot(measures, impacts, 'o', markersize=15, alpha=0.5)\n",
    "    sns.plt.xlabel(xlabels2_idts_list[mix])\n",
    "    sns.plt.ylabel('Impact of nudge')\n",
    "    if xlabels2_idts_list[mix] in ('slow/fast+idt1+idt2',):\n",
    "        sns.plt.xscale('log')\n",
    "\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to derive a useful measure\n",
    "\n",
    "$$ a e^{-bx} + c e^{-dx} + p = p + f \\cdot (a + c) $$\n",
    "$$ a e^{-bx} + c e^{-dx} = f \\cdot a + f \\cdot c $$\n",
    "$$ a (e^{-bx} - f) + c (e^{-dx} - f) = 0 $$\n",
    "$$ a (e^{-bx} - f) = - c (e^{-dx} - f) $$\n",
    "$$ -\\frac{a}{c} (e^{-bx} - f) = e^{-dx} - f $$\n",
    "$$ -\\frac{a}{c} (e^{-bx} - f) + f \\frac{a/c}{a/c} = e^{-dx} $$\n",
    "$$ -\\frac{a}{c} (e^{-bx} - f - f \\frac{1}{a/c}) = e^{-dx} $$\n",
    "$$ -\\frac{a}{c} (e^{-bx} - f \\left(\\frac{1}{a/c} + 1\\right)) = e^{-dx} $$\n",
    "$$ \\log{-\\frac{a}{c} (e^{-bx} - f \\left(\\frac{1}{a/c} + 1\\right))} = -dx $$\n",
    "$$ -\\frac{1}{d} \\log{-\\frac{a}{c} (e^{-bx} - f \\left(\\frac{1}{a/c} + 1\\right))} = x $$\n",
    "$$ -\\frac{1}{d} \\log{\\left[-\\frac{a}{c} e^{-bx} + \\frac{a}{c} f \\left(\\frac{1}{a/c} + 1\\right)\\right]} = x $$\n",
    "$$ \\log{\\left[-\\frac{a}{c} e^{-bx} + f \\left(\\frac{a}{c} + 1\\right)\\right]} = d x $$\n",
    "\n",
    "From this point it is difficult to proceed exactly. Let us do the Taylor expansion trick.\n",
    "\n",
    "$$ \\log{\\left[\\frac{-\\frac{a}{c} e^{-bx}}{f \\left(\\frac{a}{c} + 1\\right)} + 1\\right] + \\log{f \\left(\\frac{a}{c} + 1\\right)}} = d x $$\n",
    "$$ \\log{\\left[\\frac{-a/c}{a/c+1} \\frac{e^{-bx}}{f} + 1\\right] + \\log{f} + \\log{\\left(\\frac{a}{c} + 1\\right)}} = d x $$\n",
    "\n",
    "Suppose $f=e^{-1}$, then:\n",
    "\n",
    "$$ \\log{\\left[\\frac{-a/c}{a/c+1} e^{-bx-1} + 1\\right]} - 1 + \\log{\\left(\\frac{a}{c} + 1\\right)} = d x $$\n",
    "\n",
    "Suppose that $\\left| \\frac{-a/c}{a/c+1} e^{-bx-1} \\right| << 1$, which is not that crazy and true at least as $x >> 1$:\n",
    "\n",
    "$$ \\frac{-a/c}{a/c+1} e^{-bx-1} - 1 + \\log{\\left(\\frac{a}{c} + 1\\right)} = d x $$\n",
    "\n",
    "Suppose also that $a/c << 1$:\n",
    "\n",
    "$$ \\frac{-a/c}{a/c+1} e^{-bx-1} - 1 + \\frac{a}{c} = d x $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why does IDT take so long?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(ising)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %lprun -f ising.idt_per_node ising.idt_per_node(system, 'async', num_cur_states=50, num_repeats=50, num_steps=10, assume_symmetry=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrived example for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph2 =nx.empty_graphpty_graph(using=nx.DiGraph())\n",
    "for oix in range(1, 5):\n",
    "    graph2.add_edge(0, oix, {'weight': 1.0})\n",
    "for oix in range(5, 7):\n",
    "    graph2.add_edge(5, oix, {'weight': 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system2 = ising.IsingNetwork(graph2, graph2.number_of_nodes(), T=2.0, states='random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read weighted Ising network from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_weights = pd.read_csv('./Graph_min1_1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_weights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_weights['depr']['sad']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_hs = pd.read_csv('./External_min1_1.csv', index_col=0, header=0)\n",
    "vector_hs = vector_hs['externalField']\n",
    "vector_hs_list = [vector_hs[col] for col in matrix_weights.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_hs['depr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.from_numpy_matrix(np.array(matrix_weights), create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.node[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for colix, col in enumerate(matrix_weights.columns):\n",
    "    graph.node[colix]['h'] = vector_hs_list[colix]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate IDT on this network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathos.multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T=1.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psycho_net = ising.IsingNetwork(T=T)\n",
    "\n",
    "unidirectional = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psycho_net.read_graph_from_csv('./Graph_min1_1.csv', './External_min1_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "realization = ''\n",
    "if unidirectional:\n",
    "    for nxi, ny in psycho_net.graph_numbered.edges():\n",
    "    #     if nx < ny:\n",
    "        # still a bi-directional edge?\n",
    "        if psycho_net.graph_numbered.has_edge(nxi, ny) and psycho_net.graph_numbered.has_edge(ny, nxi):\n",
    "            # remove one of the edges\n",
    "            if np.random.choice([0, 1]) == 1:\n",
    "                psycho_net.graph_numbered.remove_edge(nxi, ny)\n",
    "                realization = realization + '1'\n",
    "            else:\n",
    "                psycho_net.graph_numbered.remove_edge(ny, nxi)\n",
    "                realization = realization + '0'\n",
    "else:\n",
    "    realization = '1' * psycho_net.graph_numbered.number_of_edges()\n",
    "    \n",
    "print realization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psycho_net.T = T\n",
    "\n",
    "mags = map(sum, psycho_net.go(2000, trans=trans))\n",
    "\n",
    "sns.plt.plot(mags)\n",
    "sns.plt.ylim([-psycho_net.size, +psycho_net.size])\n",
    "sns.plt.show()\n",
    "\n",
    "sns.distplot(mags, kde=False)\n",
    "sns.plt.xlim([-psycho_net.size, +psycho_net.size])\n",
    "sns.plt.show()\n",
    "\n",
    "print np.median(mags)\n",
    "print mags.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psycho_net.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Ts = np.linspace(0.01, 20.0, 10)\n",
    "medians = []\n",
    "stds = []\n",
    "zeros = []\n",
    "\n",
    "for t in Ts:\n",
    "    psycho_net.T = t\n",
    "#     psycho_net.reset_states()\n",
    "    \n",
    "    mags = map(sum, psycho_net.go(10000, trans=trans))\n",
    "    medians.append(np.median(mags))\n",
    "    stds.append(np.std(mags))\n",
    "    zeros.append(mags.count(0))\n",
    "    \n",
    "    print 'note: finished T=' + str(t)\n",
    "\n",
    "psycho_net.T = T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.plt.plot(Ts, medians, '-x')\n",
    "sns.plt.plot(Ts, stds, '-o')\n",
    "sns.plt.xlabel('Temperature')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.plt.plot(Ts, medians, '-x')\n",
    "sns.plt.plot(Ts, stds, '-o')\n",
    "sns.plt.xlabel('Temperature')\n",
    "sns.plt.show()\n",
    "\n",
    "sns.plt.plot(Ts, zeros, '-o')\n",
    "sns.plt.xlabel('Temperature')\n",
    "sns.plt.ylabel('Number of zero magnetization')\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assume_symmetry = False  # should set to False if there are external magnetic fields, at least (which is symmetry breaking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_to_reuse = True\n",
    "\n",
    "time_before = time.time()\n",
    "mi_per_node = None\n",
    "psycho_idt_resp = None\n",
    "if try_to_reuse:\n",
    "    try:\n",
    "#         print 'debug: will try file:', './psycho_idt_resp_T%s_uni%s.pickle' % (psycho_net.T, int(unidirectional))\n",
    "        with open('./psycho_idt_resp_T%s_uni%s.pickle' % (psycho_net.T, int(unidirectional)), 'rb') as fin:\n",
    "            psycho_idt_resp = pickle.load(fin)\n",
    "\n",
    "        with open('./mi_per_node_T%s_uni%s.png' % (psycho_net.T, int(unidirectional)), 'rb') as fin:\n",
    "            mi_per_node = pickle.dump(fin)\n",
    "    except:\n",
    "        mi_per_node = None\n",
    "        psycho_idt_resp = None\n",
    "    else:\n",
    "        print 'note: reused previously computed result from file', './psycho_idt_resp_T%s_uni%s.pickle' % (psycho_net.T, int(unidirectional))\n",
    "if mi_per_node is None or psycho_idt_resp is None:\n",
    "    psycho_idt_resp, mi_per_node = ising.rel_idt_per_node(psycho_net, trans, num_cur_states=300, num_repeats=300, \n",
    "                                                          num_steps=70, return_also_mi=True, assume_symmetry=assume_symmetry)\n",
    "print time.time() - time_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for nix in xrange(psycho_net.size):\n",
    "    sns.plt.plot(mi_per_node[nix][:])\n",
    "sns.plt.xlabel('Time step $t$')\n",
    "sns.plt.xlabel('Mutual information I[X(0), x(t)]')\n",
    "sns.plt.savefig('./mi_over_time_per_node_full_T%s_uni%s.png' % (psycho_net.T, int(unidirectional)))\n",
    "sns.plt.show()\n",
    "\n",
    "for nix in xrange(psycho_net.size):\n",
    "    sns.plt.plot(mi_per_node[nix][:][:min(20,len(mi_per_node[nix][:]))])\n",
    "sns.plt.xlabel('Time step $t$')\n",
    "sns.plt.xlabel('Mutual information I[X(0), x(t)]')\n",
    "sns.plt.title('Zoomed in')\n",
    "sns.plt.savefig('./mi_over_time_per_node_firstpart_T%s_uni%s.png' % (psycho_net.T, int(unidirectional)))\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idt_per_node = zip(matrix_weights.columns, psycho_idt_resp.decay_times)\n",
    "\n",
    "with open('./idt_per_node_T%s_uni%s.csv' % (psycho_net.T, int(unidirectional)), 'wb') as fout:\n",
    "    csvw = csv.writer(fout)\n",
    "    csvw.writerows(idt_per_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_degrees = [psycho_net.graph_numbered.degree(nix, weight='weight') for nix in range(psycho_net.size)]\n",
    "weighted_out_degrees = [psycho_net.graph_numbered.out_degree(nix, weight='weight') for nix in range(psycho_net.size)]\n",
    "weighted_in_degrees = [psycho_net.graph_numbered.in_degree(nix, weight='weight') for nix in range(psycho_net.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bcdist = nx.centrality.betweenness_centrality(psycho_net.graph_numbered, weight='weight')\n",
    "bcs = [bcdist[nix] for nix in range(psycho_net.size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psycho_net.graph_numbered.out_degree(0, weight='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.plt.plot(weighted_degrees, psycho_idt_resp.decay_times, 'o')\n",
    "sns.plt.xlabel('Weighted degree')\n",
    "sns.plt.ylabel('IDT')\n",
    "sns.plt.savefig('./scatter_idt_vs_weighted_degree_T%s_uni%s.png' % (psycho_net.T, int(unidirectional)))\n",
    "sns.plt.show()\n",
    "\n",
    "sns.plt.plot(np.abs(weighted_degrees), psycho_idt_resp.decay_times, 'o')\n",
    "sns.plt.xlabel('Abs[Weighted degree]')\n",
    "sns.plt.ylabel('IDT')\n",
    "sns.plt.savefig('./scatter_idt_vs_abs_weighted_degree_T%s_uni%s.png' % (psycho_net.T, int(unidirectional)))\n",
    "sns.plt.show()\n",
    "\n",
    "sns.plt.plot(weighted_out_degrees, psycho_idt_resp.decay_times, 'o')\n",
    "sns.plt.xlabel('Weighted out-degree')\n",
    "sns.plt.ylabel('IDT')\n",
    "sns.plt.show()\n",
    "\n",
    "sns.plt.plot(np.abs(weighted_out_degrees), psycho_idt_resp.decay_times, 'o')\n",
    "sns.plt.xlabel('Abs[Weighted out-degree]')\n",
    "sns.plt.ylabel('IDT')\n",
    "sns.plt.show()\n",
    "\n",
    "sns.plt.plot(weighted_in_degrees, psycho_idt_resp.decay_times, 'o')\n",
    "sns.plt.xlabel('Weighted in-degree')\n",
    "sns.plt.ylabel('IDT')\n",
    "sns.plt.show()\n",
    "\n",
    "sns.plt.plot(np.abs(weighted_in_degrees), psycho_idt_resp.decay_times, 'o')\n",
    "sns.plt.xlabel('Abs[Weighted in-degree]')\n",
    "sns.plt.ylabel('IDT')\n",
    "sns.plt.show()\n",
    "\n",
    "print '----------------'\n",
    "\n",
    "sns.plt.plot(bcs, psycho_idt_resp.decay_times, 'o')\n",
    "sns.plt.xlabel('Betweenness centrality (weighted)')\n",
    "sns.plt.ylabel('IDT')\n",
    "sns.plt.savefig('./scatter_idt_vs_betweenness_T%s_uni%s.png' % (psycho_net.T, int(unidirectional)))\n",
    "sns.plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./psycho_idt_resp_T%s_uni%s.pickle' % (psycho_net.T, int(unidirectional)), 'wb') as fout:\n",
    "    pickle.dump(psycho_idt_resp, fout)\n",
    "    \n",
    "with open('./mi_per_node_T%s_uni%s.png' % (psycho_net.T, int(unidirectional)), 'wb') as fout:\n",
    "    pickle.dump(mi_per_node, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random networks\n",
    "\n",
    "Identify the largest driver node (largest IDT) in randomly generated networks and study the topological features of this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsys = 10\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "241px",
    "width": "342px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "350px",
    "left": "7px",
    "right": "1115px",
    "top": "114px",
    "width": "179px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
